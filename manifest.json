{
  "$schema": "https://stina.app/schemas/extension-manifest.json",
  "id": "ollama-provider",
  "name": "Ollama AI Provider",
  "version": "1.0.5",
  "description": "Connect Stina to your local Ollama instance for private, offline AI conversations.",
  "type": "provider",
  "author": {
    "name": "Stina Team",
    "url": "https://github.com/einord"
  },
  "repository": "https://github.com/einord/stina-ext-ollama",
  "license": "MIT",
  "engines": {
    "stina": ">=0.5.0"
  },
  "platforms": ["web", "electron", "tui"],
  "main": "index.js",

  "permissions": [
    "network:*",
    "provider.register"
  ],

  "contributes": {
    "providers": [
      {
        "id": "ollama",
        "name": "Ollama",
        "description": "Local AI models via Ollama",
        "suggestedDefaultModel": "llama3.2:8b",
        "defaultSettings": {
          "url": "http://localhost:11434"
        },
        "configSchema": {
          "order": ["url"],
          "properties": {
            "url": {
              "type": "url",
              "title": "Server URL",
              "description": "URL to your Ollama server",
              "placeholder": "http://localhost:11434",
              "default": "http://localhost:11434",
              "required": true
            }
          }
        }
      }
    ]
  }
}
